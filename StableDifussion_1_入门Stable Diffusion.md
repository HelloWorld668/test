在开始之前，我想先阐述一下我对AI绘画的理解：其本质在于成为人的画笔助手，即由人提出创意方案，而AI负责完成具体的绘画过程。

本文撰写的初衷源于我在研究Stable Diffusion过程中，受到了诸多复杂参数和模型专业术语的挫败。因此，在学习掌握后，我希望通过这篇教程帮助完全零基础的初学者入门，即便他们没有编程和绘画能力。这将有助于我们迅速判断这项技术是否具有价值，以及是否适合作为副业选择。

本文将仅介绍最基本的操作，并逐步引导读者完成一个实际案例，使大家能够掌握AI绘图的整个流程。我认为，在了解其背后的原理或大致了解其功能范围后，就可以判断这项技术的价值以及对自己的帮助程度。

> 欢迎关注我的公众号：更AI。第一时间了解前沿行业消息、分享深度技术干货、获取优质学习资源

# 软件总览

先给大家看一下我用Stable Diffusion（以下称SD）画出来的图。也是我学习1个小时的成果。

![image-20230426204100137](https://pic.crud.top/pic/typora/2023/05/24/image-20230426204100137.png)

## 软件安装与打开

关于软件的安装，以及环境的部署，建议直接下载大佬们网上的整合包。这里推荐秋葉aaaki大佬的整合包，链接在这里：https://www.bilibili.com/video/BV17d4y1C73R/?spm_id_from=333.788.video.desc.click&vd_source=bd8f1862d445f4e01d7c1f49857dd474


这里建议直接安装大佬的一键整合包，极大地降低了安装难度，对小白非常友好。打开后如图所示。

![image-20230426204239990](https://pic.crud.top/pic/typora/2023/05/24/image-20230426204239990.png)

然后点击“一键启动”，稍等片刻后会自动打开这个浏览器界面，就可以使用了（第一次打开时会有点久）

## 流程和界面介绍

这里不去介绍sd的实现模型，只介绍一下我们所看到的呈现模型。可以理解为，就像是在做一道菜一样。首先准备原料（提示词和参数），然后按照菜谱（模型）来烹饪，让原料经历各种处理，最后就得到了可供品尝的美食（图像）。

1. 选择模型
2. 输入提示词
3. 调整参数
4. 点击生成
5. ![image-20230426204444130](https://pic.crud.top/pic/typora/2023/05/24/image-20230426204444130.png)

# 模型

## 五大分类

正如前面所提到的，模型可以看作是我们烹饪时所使用的菜谱。每个模型都具有自己的特点，例如二次元画风、CG画风等。

在Stable Diffusion（简称SD）中，目前共有五种类型的模型：

1. 基础底模型（单独使用）：Checkpoint
2. 辅助模型（配合底模型使用）：Embedding，LoRa，Hypernetwork
3. 美化模型：VAE

这些模型之间的区别和使用方式可以类比为烹饪中的技巧：基础底模型相当于“炒”，辅助模型则类似于“爆炒、小炒”，最后的美化模型类似于更细节化的烹饪方法，如“盐爆、葱爆、油爆”等。

在SD中，基础底模型是必需的，且只能有一种，而其他模型没有限制，可以没有，也可以使用一种或多种。

## 模型的下载和使用

下载模型时，需要注意对应的类别。以下以最常用的基础底模型（Checkpoint）和LoRa模型为例，介绍它们的使用方法：

1. 首先，需要确定下载的模型属于哪个类别。如果从前面提到的两个网站下载，下载时就能了解到模型的类别。若从其他渠道（如百度网盘链接）下载，可以借助一个网站获取模型类别：https://spell.novelai.dev/
2. 将模型文件放入相应文件夹。同时，可以放入一张模型预览图，将图片名称修改为与模型相同，方便后续选择。在模型命名时，可以用“/”对模型进行分类整理。例如，若一个模型与二次元相关，可以命名为“二次元/XXX”。
3. 接下来是模型的调用。对于基础底模型，可以直接在界面上选择。如果没有找到，点击右侧的刷新按钮即可。VAE模型在后续下拉框中选择。通常使用默认选项，如果生成的图像过于灰暗，再考虑使用VAE模型。对于其他模型，先点击界面上的图标，再点击想要使用的模型。这时，正向提示词输入框会显示相应的模型。若要取消调用，再次点击模型或直接在输入框中删除即可。对于某些模型，还需要在正向提示词输入框中输入特定的触发词，以使模型发挥效果。

## 提示词

提示词也就是我们对AI的指令。

1. 正向提示词：即对画面的描述，例如，一个女孩，月亮，吉他，沙发等
2. 反向提示词：指你不想在画面中出现的元素或属性。例如，低质量，畸形的手等

### 基本规范

这里有两条基本规范需要注意一下：

1. 提示词包括标点符号全部用英文的
2. 单词、短语、句子基本上是等效的。例如“1gril、sofa、sitting”与“A girl sitting on the sofa”对SD来说是等效的。

### 书写提示词的整体思路

在给正向提示词的时候，我们一般通过分类描述的方式来给出。具体可以分为以下三类：整体描述、主体、场景。

### 整体描述

这里包括四个方面：
画质：高画质还是中等画质或者低画质，2k、或者4k等等
画风：CG、二次元、真人等
镜头：画面中人物的占比，半身像还是全身像
色调：冷色调或暖色调

### 主体

对于人物主体的描述包括三个方面：头部、服饰、姿势

### 头部

这里面包括的内容和我们玩游戏时捏脸的内容差不多，具体也就是包括这些内容：

1. 眼睛大小、颜色和形状，鼻子大小和形状，嘴巴大小和形状，下巴形状等等。
2. 皮肤颜色和纹理：人物的皮肤颜色和纹理，例如光滑或有皱纹的皮肤等等。
3. 面部特征细节：进一步描述人物的面部细节，例如眼睛的纹理、唇色、发色，等等。

### 服饰

包括衣服，裤子、鞋以及其他更细节的比如袜子之类的

### 姿势

即人物的姿势，坐立跑等

### 场景

基础的场景描述一般包括三个内容：时间、地点、天气，进阶的表达可以加入一些细节，例如天空中的蝴蝶、花瓣等。

# 提示词的语法

仅仅有了提示词还不够，我们还需要知道怎么把提示词组成SD可以识别的格式。

### 提示词的连接方式

1. 不同的提示词之间用英文逗号分隔
2. 提示词越靠前，权重越高，所以主体应该放在前面

### 提示词的强化/弱化方式

1. (提示词:权重数值)。其中这个数值的取值范围是0.1～100，默认是1，小于1是弱化，大于1是强化。例如：(a girl:0.8)

2. (提示词)[提示词]。提示词外面加()表示强化，加[]表示弱化。允许套多层来增强强化或弱化的程度。例如：((a girl))

推荐几个提示词的网站。在掌握了提示词的基本用法后，再去看这些网站就会更得心应手一些。

1. https://prompttool.com/NovelAI?goLogin=1
2. https://wolfchen.top/tag/
3. https://moonvy.com/apps/ops/
4. http://poe.com/ChatGpt
5. https://magic-tag.netlify.app/#

# 参数

这里不想去说太多参数的官方解释，而且，在初期并不是所有的参数都需要了解，所以这里直接用通俗易懂的语言来给大家介绍一下需要用到的参数是什么，以及怎么用。

## 采样方法

这里的原理比较复杂，笔者这里直接抛出结论：一般情况下使用DPM++ 2M或DPM++ 2M Karras或UniPC，想要一些变化，就用Euler a、DPM++ SDE、DPM++ SDE Karras、DPM2 a Karras。

## 迭代步数

这里指的是sd用多少步把你的描述画出来。这里先给出结论，一般20到40步就足够了。迭代步数每增加一步迭代，都会给AI更多的机会去比对提示和当前结果，并进行调整。更高的迭代步数需要更多的计算时间。但并不意味着步数越高，质量越好。

## 面部修复

根据个人喜好开关，这个对最终成像效果影响不大。

## 平铺图

这个一般用不到。

## 高分辨率修复

通俗来说，就是以重新绘制的方式对图像进行放大，并且在放大的同时补充一些细节。


打开后，这里会出现一些子参数。

## 放大算法：*

用默认值即可。

## 高分迭代步数：

一般选在10~20即可。

## 重绘幅度

一般是0.5~0.8之间。幅度过小，效果不好，幅度过大时，和原图差异太大。

## 放大倍率

这个比较好理解，就是指最终的图原来图的分辨率的比值。例如，默认生成的图是512_512，设定为2倍后，最终产出的图就是1024_1024。

## 总批次数和单批数量

这个是指一次性出图的数量。以搬砖为例，同样是搬4块砖，体力好的人可以一次搬4块，只搬一次，对应到SD中，就是总批次数是1，单批数量为4；而体力不好的人一次只能搬一块，需要搬4次，对应到SD中，就是总批次数是4，单批数量为1。一般而言，如果不是顶级显卡，我们都会保持单批数量为1，去改变总批次数来增加一次性出图的数量。

## 提示词引导系数

最终生成的画面和你的描述词的趋近程度，一般设置为7~15之间，太高也会出现问题。

## 随机数种子

随机数种子就像在做一道菜时加入的特定调料，它可以影响整道菜的味道。在这个图像生成方法中，随机数种子就是一个特定的数值或代码，可以影响最终生成的图像的过程，就像特定的调料会影响整道菜的味道一样。不同的随机数种子会生成不同的图像，就像加入不同的调料会让同一道菜变成不同的味道。每个图都会有它对应的随机数种子，如果想还原这张图，或者绘制一张相似的图，必须保证这个值是相同的。随机数种子不变的情况下，即使模型发生了改变，最终生成图的大概结构和配色也会有一定相似性。就像是无论是以土豆还是以茄子作为食材，只要加入的都是甜辣酱，最终的味道是差不多的。我们可以在输入框中输入特定的值，以保证随机数种子固定，否则可以点一下旁边的骰子icon，变成-1（-1就指的是随机值）使得模型采用随机的值来生成图像。

## 变异随机种子

在理解了随机种子之后，我们再去理解变异随机种子就更好理解了。变异随机种子相当于又加入了第二种特定调料。而后面的变异强度就指的是两种调料的占比，数值越大，越接近第二种。数值为0时，就指的是完全不用变异随机种子。一般是用于确定了图后，对图生成其他相似画面的图像。例如，在做ip时，通过加入变异随机种子，可以实现画面内容不变的情况下，生成带有些许差异的画，从中选择更优的。

> 欢迎关注我的公众号：更AI。第一时间了解前沿行业消息、分享深度技术干货、获取优质学习资源
